{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6311576",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Imbalanced-data\" data-toc-modified-id=\"Imbalanced-data-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Imbalanced data</a></span></li><li><span><a href=\"#Import\" data-toc-modified-id=\"Import-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Import</a></span></li><li><span><a href=\"#Load-data\" data-toc-modified-id=\"Load-data-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Load data</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-categorical-variables\" data-toc-modified-id=\"Create-categorical-variables-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Create categorical variables</a></span></li><li><span><a href=\"#Split-train-and-test-set\" data-toc-modified-id=\"Split-train-and-test-set-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Split train and test set</a></span></li><li><span><a href=\"#Encoding-Categorical-Variables\" data-toc-modified-id=\"Encoding-Categorical-Variables-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Encoding Categorical Variables</a></span></li><li><span><a href=\"#Feature-Scaling---StandardScaler\" data-toc-modified-id=\"Feature-Scaling---StandardScaler-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Feature Scaling - StandardScaler</a></span></li></ul></li><li><span><a href=\"#Building-a-model\" data-toc-modified-id=\"Building-a-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Building a model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d63a1",
   "metadata": {},
   "source": [
    "# Bank Marketing Builing Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b95306",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "__The main goal of this project is to predict if the client will subscribe a term deposit (variable y).__ I will show how to approach developing a model to predict client's subscriptions using an imbalanced dataset. \n",
    "\n",
    "The dataset is provided by [UCI-Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/bank+marketing). The data contains direct marketing campaigns (phone calls) of a Portuguese banking institution. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be 'yes' or 'no' subscribed. \n",
    "\n",
    "\n",
    "### Feature Engineering\n",
    "The original dataset has 10 numerical variables (9 continuous and 1 discrete), 10 categorical variables. I created 2 categorical variables `age_group` and `pdays_group` by using `age` and `pdays`, and removed the original variables. \n",
    "Also, I removed `duration` variable due to the given information: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "\n",
    "So, the final dataset has 11 numerical variables and 8 categorical variables. \n",
    "\n",
    "Before building a model, we need to encode categorical variables as numerical values. So, I will use integer encoding by using feature engine package. Also, I will use StandardScaler from sklearn to scale all numerical variables. \n",
    "\n",
    "I'll show the feature engineering process in this notebook with less detail, so if you want to see more, please take a look at [Bank_Marketing_EDA.ipynb](https://github.com/yejiseoung/BankMarketing/blob/develop/Bank_Marketing_EDA.ipynb) and [Bank_Marketing_FeatureEngineering.ipynb](https://github.com/yejiseoung/BankMarketing/blob/develop/Bank_Marketing_FeatureEngineering.ipynb). You can find the visualizations and more detail in those notebooks. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Imbalanced data\n",
    "We have a classification problem. The target is a binary variable (no-yes), and it shows 89% of no and 11% of yes responses. This dataset is a typical imbalanced data which means that datasets have many more instances of certain classes (no - 89%) than of others (yes - 11%). Since most machine learning algorithms assume balanced distributions, samples from the minority class (in this case, yes label) are likely misclassified. So, we need to deal with this very carefully. Through the notebook, I will implement EasyEnsemble technique which is an ensemble algorithms that were designed to work with imbalanced datasets. \n",
    "\n",
    "You might wonder why I won't use under- or over-sampling techniques. I tried all possible techinques to balance imbalanced dataset and none of under- or over-sampling techinques did not improve the model performance. You can find the whole process in [Bank_Marketing_BalancingSampling.ipynb](https://github.com/yejiseoung/BankMarketing/blob/develop/Bank_Marketing_BalancingSampling.ipynb)\n",
    "\n",
    "\n",
    "- __Reference__: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9227e",
   "metadata": {},
   "source": [
    "I tried to figure out if we need to perform feature selection, but the models did not improve after selecting features, so I will use all variables here. If you want to see the feature selection process, please see [Bank_Marketing_FeatureSelection.ipynb](https://github.com/yejiseoung/BankMarketing/blob/develop/Bank_Marketing_FeatureSelection.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563168d8",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30af085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/yejiseoung/Dropbox/My Mac (Yejis-MacBook-Pro.local)/Documents/Projects/BankMarketing'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de78654",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/Users/yejiseoung/Dropbox/My Mac (Yejis-MacBook-Pro.local)/Documents/Projects/BankMarketing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8624225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the model \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    AdaBoostClassifier)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score,\n",
    "    accuracy_score,\n",
    "    recall_score,\n",
    "    precision_score\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# for feature engineering\n",
    "from feature_engine import encoding as ce\n",
    "\n",
    "\n",
    "# for cross-validation\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# for ensemble sampling\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "# for feature selection\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# for feature selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11c8e37",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93c7aa86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>307</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  duration  campaign  pdays  previous     poutcome  \\\n",
       "0   may         mon       261         1    999         0  nonexistent   \n",
       "1   may         mon       149         1    999         0  nonexistent   \n",
       "2   may         mon       226         1    999         0  nonexistent   \n",
       "3   may         mon       151         1    999         0  nonexistent   \n",
       "4   may         mon       307         1    999         0  nonexistent   \n",
       "\n",
       "   emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "1           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "2           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "3           1.1          93.994          -36.4      4.857       5191.0  no  \n",
       "4           1.1          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path/'bank.csv', delimiter=';')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ffade93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     36548\n",
       "yes     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have imbalanced data\n",
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e84bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values\n",
    "[var for var in data.columns if data[var].isnull().mean() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2ecf8",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e30fed",
   "metadata": {},
   "source": [
    "### Create categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b58a29c",
   "metadata": {},
   "source": [
    "Here, I will drop `duration` and create `age_group` and `pdays_group` by using `age` and `pdays` variables, and drop the original variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbecdea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 20)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop('duration', axis=1, inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672b9b0",
   "metadata": {},
   "source": [
    "`age`: 17-30 for young adult, 31-40, 41-50, 51-60, and more than 61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9a1c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's divide age into the buckets \n",
    "buckets = [16, 30, 40, 50, 60, 100]\n",
    "\n",
    "# bucket labels\n",
    "labels = ['17-30', '31-40', '41-50', '51-60', '>60']\n",
    "\n",
    "# discretization\n",
    "data['age_group'] = pd.cut(data['age'], bins=buckets, labels=labels, include_lowest=True)\n",
    "data['age_group'] = data['age_group'].astype('O') # change dtype\n",
    "\n",
    "# drop the original age column\n",
    "data.drop('age', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f26650f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    51-60\n",
       "1    51-60\n",
       "2    31-40\n",
       "3    31-40\n",
       "4    51-60\n",
       "Name: age_group, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['age_group'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674fe471",
   "metadata": {},
   "source": [
    "`pdays`: 1w (less than 7days), 2w (less than 14 days), and >2w (more than 14days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55ce9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdays has 999 values which mean that \n",
    "# client was not previous contacted. \n",
    "# I will change 999 to -1 \n",
    "data['pdays'] = data['pdays'].replace(999, -1)\n",
    "\n",
    "# let's divide pdays into 3 groups\n",
    "bins = [0, 7, 14, 30]\n",
    "\n",
    "# labels\n",
    "labels = ['1w', '2w', '>2w']\n",
    "\n",
    "data['pdays_group'] = pd.cut(data['pdays'], bins=bins, labels=labels, \n",
    "                             include_lowest=False) # False makes -1 value to missing values\n",
    "\n",
    "# fill missing values to Not contacted\n",
    "data['pdays_group'] = data['pdays_group'].astype('O')\n",
    "data['pdays_group'].fillna('Not contacted', inplace=True)\n",
    "\n",
    "# drop the original column\n",
    "data.drop('pdays', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ab94c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Not contacted\n",
       "1    Not contacted\n",
       "2    Not contacted\n",
       "3    Not contacted\n",
       "4    Not contacted\n",
       "Name: pdays_group, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['pdays_group'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e28d894d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>campaign</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "      <th>age_group</th>\n",
       "      <th>pdays_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>51-60</td>\n",
       "      <td>Not contacted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>51-60</td>\n",
       "      <td>Not contacted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Not contacted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Not contacted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "      <td>51-60</td>\n",
       "      <td>Not contacted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         job  marital    education  default housing loan    contact month  \\\n",
       "0  housemaid  married     basic.4y       no      no   no  telephone   may   \n",
       "1   services  married  high.school  unknown      no   no  telephone   may   \n",
       "2   services  married  high.school       no     yes   no  telephone   may   \n",
       "3     admin.  married     basic.6y       no      no   no  telephone   may   \n",
       "4   services  married  high.school       no      no  yes  telephone   may   \n",
       "\n",
       "  day_of_week  campaign  previous     poutcome  emp.var.rate  cons.price.idx  \\\n",
       "0         mon         1         0  nonexistent           1.1          93.994   \n",
       "1         mon         1         0  nonexistent           1.1          93.994   \n",
       "2         mon         1         0  nonexistent           1.1          93.994   \n",
       "3         mon         1         0  nonexistent           1.1          93.994   \n",
       "4         mon         1         0  nonexistent           1.1          93.994   \n",
       "\n",
       "   cons.conf.idx  euribor3m  nr.employed   y age_group    pdays_group  \n",
       "0          -36.4      4.857       5191.0  no     51-60  Not contacted  \n",
       "1          -36.4      4.857       5191.0  no     51-60  Not contacted  \n",
       "2          -36.4      4.857       5191.0  no     31-40  Not contacted  \n",
       "3          -36.4      4.857       5191.0  no     31-40  Not contacted  \n",
       "4          -36.4      4.857       5191.0  no     51-60  Not contacted  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d29481",
   "metadata": {},
   "source": [
    "Change no, yes values to 0, 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63ea492",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['y'] = data['y'].map({'no':0, 'yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727d2cf",
   "metadata": {},
   "source": [
    "### Split train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fe009c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categorical variables: 12\n",
      "Number of Numerical variables: 7\n"
     ]
    }
   ],
   "source": [
    "# Create lists for categorical and numerical variables\n",
    "\n",
    "cat_vars = [var for var in data.columns if var != 'y' and data[var].dtype=='O']\n",
    "num_vars = [var for var in data.columns if var != 'y' and data[var].dtype!='O']\n",
    "\n",
    "print('Number of Categorical variables: {}'.format(len(cat_vars)))\n",
    "print('Number of Numerical variables: {}'.format(len(num_vars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fca345da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28831, 19), (12357, 19))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.drop('y', axis=1),\n",
    "    data['y'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaed4e66",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4301072b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder(encoding_method='arbitrary',\n",
       "               variables=['job', 'marital', 'education', 'default', 'housing',\n",
       "                          'loan', 'contact', 'month', 'day_of_week', 'poutcome',\n",
       "                          'age_group', 'pdays_group'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using OrdinalEncoder from feature-engine\n",
    "\n",
    "ordinal_enc = ce.OrdinalEncoder(\n",
    "    encoding_method='arbitrary',\n",
    "    variables=cat_vars)\n",
    "\n",
    "ordinal_enc.fit(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d726888",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = ordinal_enc.transform(X_train)\n",
    "X_test = ordinal_enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26271b8",
   "metadata": {},
   "source": [
    "### Feature Scaling - StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21410ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit the scaler to the train set, it will learn the parameters\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# transform train and test set\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a2f15",
   "metadata": {},
   "source": [
    "## Building a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd08b4e",
   "metadata": {},
   "source": [
    "EasyEnsemble involves creating balanced samples of the training datset by selecting all examples from the minority class and a subset from the majority class. Rather than using pruned decision trees, boosted decision trees are used on each subset, specifically the AdaBoost algorithm. \n",
    "\n",
    "The EasyEnsembleClassifier class from the imbalanced-learn library provides an implmentation of the easy ensemble technique. I will use EasyEnsembleClassifier in this notebook. \n",
    "\n",
    "We can choose the classifiers to build the best model, so I will use RandomSearchCV to find the best hyperparameters and estimators for this problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd7d471b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RFs(X_train, X_test, y_train, y_test):\n",
    "    \"\"\" Function to evaluate random forests performance\"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators=20)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = rf.predict_proba(X_train)\n",
    "    print('RF roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = rf.predict_proba(X_test)\n",
    "    print('RF roc-auc: {}'.format(roc_auc_score(y_test, pred[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "daf4e86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_easy(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Function to evaluate EasyEnsemble performance\"\"\"\n",
    "    easy = EasyEnsembleClassifier(\n",
    "        n_estimators=20,\n",
    "        sampling_strategy='auto', \n",
    "        n_jobs=1,\n",
    "        random_state=42)\n",
    "    \n",
    "    easy.fit(X_train, y_train)\n",
    "    \n",
    "    print('Train set')\n",
    "    pred = easy.predict_proba(X_train)\n",
    "    print('EasyEnsemble roc-auc: {}'.format(roc_auc_score(y_train, pred[:,1])))\n",
    "    \n",
    "    print('Test set')\n",
    "    pred = easy.predict_proba(X_test)\n",
    "    print('EasyEnsemble roc-auc: {}'.format(roc_auc_score(y_test, pred[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d723c1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "RF roc-auc: 0.9985199423420013\n",
      "Test set\n",
      "RF roc-auc: 0.7568164657379993\n"
     ]
    }
   ],
   "source": [
    "# base model for RF\n",
    "run_RFs(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a984eca",
   "metadata": {},
   "source": [
    "Random forest shows over-fitting, and we can solve this problem by tuning the hyperparamters, but I won't do it here because I wanted to create base model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bfa89447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set\n",
      "EasyEnsemble roc-auc: 0.7978208876756269\n",
      "Test set\n",
      "EasyEnsemble roc-auc: 0.7941023799583999\n"
     ]
    }
   ],
   "source": [
    "# base model\n",
    "run_easy(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b3723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up classifiers\n",
    "easy = EasyEnsembleClassifier(random_state=42)\n",
    "ada = AdaBoostClassifier()\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# determine the hyperparamter space\n",
    "param_grid = dict(\n",
    "    n_estimators=stats.randint(10, 200),\n",
    "    sampling_strategy = ['float', 'auto'],\n",
    "    base_estimator=[ada, gbm]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9426e712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=EasyEnsembleClassifier(random_state=42),\n",
       "                   n_iter=60, n_jobs=1,\n",
       "                   param_distributions={'base_estimator': [AdaBoostClassifier(),\n",
       "                                                           GradientBoostingClassifier()],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f8a596bf850>,\n",
       "                                        'sampling_strategy': ['float', 'auto']},\n",
       "                   random_state=42, scoring='roc_auc')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = RandomizedSearchCV(easy,\n",
    "                           param_grid,\n",
    "                           scoring='roc_auc',\n",
    "                           cv=5,\n",
    "                           n_iter=60,\n",
    "                           random_state=42,\n",
    "                           n_jobs=1,\n",
    "                           refit=True)\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "565e04a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': GradientBoostingClassifier(),\n",
       " 'n_estimators': 98,\n",
       " 'sampling_strategy': 'auto'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "765a2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_base_estimator</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_sampling_strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>189</td>\n",
       "      <td>float</td>\n",
       "      <td>{'base_estimator': AdaBoostClassifier(), 'n_es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.199114</td>\n",
       "      <td>0.054027</td>\n",
       "      <td>2.347370</td>\n",
       "      <td>0.016289</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>116</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'base_estimator': AdaBoostClassifier(), 'n_es...</td>\n",
       "      <td>0.781891</td>\n",
       "      <td>0.806603</td>\n",
       "      <td>0.782368</td>\n",
       "      <td>0.775883</td>\n",
       "      <td>0.802661</td>\n",
       "      <td>0.789881</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>30</td>\n",
       "      <td>float</td>\n",
       "      <td>{'base_estimator': AdaBoostClassifier(), 'n_es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>84</td>\n",
       "      <td>float</td>\n",
       "      <td>{'base_estimator': GradientBoostingClassifier(...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.171960</td>\n",
       "      <td>0.114343</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>126</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'base_estimator': GradientBoostingClassifier(...</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.815365</td>\n",
       "      <td>0.784953</td>\n",
       "      <td>0.787191</td>\n",
       "      <td>0.809546</td>\n",
       "      <td>0.798051</td>\n",
       "      <td>0.012206</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.006823      0.001288         0.000000        0.000000   \n",
       "1      15.199114      0.054027         2.347370        0.016289   \n",
       "2       0.004379      0.000160         0.000000        0.000000   \n",
       "3       0.004572      0.000034         0.000000        0.000000   \n",
       "4      55.171960      0.114343         0.782275        0.018310   \n",
       "\n",
       "           param_base_estimator param_n_estimators param_sampling_strategy  \\\n",
       "0          AdaBoostClassifier()                189                   float   \n",
       "1          AdaBoostClassifier()                116                    auto   \n",
       "2          AdaBoostClassifier()                 30                   float   \n",
       "3  GradientBoostingClassifier()                 84                   float   \n",
       "4  GradientBoostingClassifier()                126                    auto   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'base_estimator': AdaBoostClassifier(), 'n_es...                NaN   \n",
       "1  {'base_estimator': AdaBoostClassifier(), 'n_es...           0.781891   \n",
       "2  {'base_estimator': AdaBoostClassifier(), 'n_es...                NaN   \n",
       "3  {'base_estimator': GradientBoostingClassifier(...                NaN   \n",
       "4  {'base_estimator': GradientBoostingClassifier(...           0.793200   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0                NaN                NaN                NaN                NaN   \n",
       "1           0.806603           0.782368           0.775883           0.802661   \n",
       "2                NaN                NaN                NaN                NaN   \n",
       "3                NaN                NaN                NaN                NaN   \n",
       "4           0.815365           0.784953           0.787191           0.809546   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0              NaN             NaN               60  \n",
       "1         0.789881        0.012322               30  \n",
       "2              NaN             NaN               38  \n",
       "3              NaN             NaN               39  \n",
       "4         0.798051        0.012206                7  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(search.cv_results_)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5331b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_base_estimator</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_sampling_strategy</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>98</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.798117</td>\n",
       "      <td>0.012181</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>113</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.798109</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>113</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.798109</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>120</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.798081</td>\n",
       "      <td>0.012211</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>90</td>\n",
       "      <td>auto</td>\n",
       "      <td>0.798061</td>\n",
       "      <td>0.012227</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           param_base_estimator param_n_estimators param_sampling_strategy  \\\n",
       "0  GradientBoostingClassifier()                 98                    auto   \n",
       "1  GradientBoostingClassifier()                113                    auto   \n",
       "2  GradientBoostingClassifier()                113                    auto   \n",
       "3  GradientBoostingClassifier()                120                    auto   \n",
       "4  GradientBoostingClassifier()                 90                    auto   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.798117        0.012181                1  \n",
       "1         0.798109        0.012196                2  \n",
       "2         0.798109        0.012196                2  \n",
       "3         0.798081        0.012211                4  \n",
       "4         0.798061        0.012227                5  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by='mean_test_score', ascending=False, inplace=True)\n",
    "results.reset_index(drop=True, inplace=True)\n",
    "results[[\n",
    "    'param_base_estimator', 'param_n_estimators', 'param_sampling_strategy',\n",
    "    'mean_test_score', 'std_test_score', 'rank_test_score'\n",
    "]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59b547eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train roc_auc:  0.8198223065247972\n",
      "Test roc_auc:  0.8080442775198536\n"
     ]
    }
   ],
   "source": [
    "X_train_preds = search.predict_proba(X_train)[:,1]\n",
    "X_test_preds = search.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Train roc_auc: ', roc_auc_score(y_train, X_train_preds))\n",
    "print('Test roc_auc: ', roc_auc_score(y_test, X_test_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f70680f",
   "metadata": {},
   "source": [
    "By tuning hyperparameters of EasyEnsembleClassifier, we got slightly improved performance of the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
